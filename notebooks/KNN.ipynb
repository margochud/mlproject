{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wux29Umsas9q"
   },
   "source": [
    "# KNN, рак и спам\n",
    "__Суммарное количество баллов: 12__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[HSE][MS][ML][HW01] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "В этом домашнем задании Вам предлагается при помощи классификации методом k ближайших соседей научиться отличать тип опухоли в организме, а так же определять сообщения со спамом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bEAo10F-as99"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import pandas as pd\n",
    "from typing import NoReturn, Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkdExsVzas-C"
   },
   "source": [
    "### Задание 1 (1 балл)\n",
    "Для начала работы нам необходимо научиться читать набор данных. Всего мы будем работать с двумя наборами данных.\n",
    "\n",
    "__Cancer.csv__ - выборка данных о пациентах с доброкачественными и злокачественными опухолями. Задача - научиться их отличать.\n",
    "\n",
    "__Spam.csv__ - набор данных большего размера. Он содержит некоторую статистику по сообщениям, а так же метку, является ли сообщение спамом. Задача - научиться автоматически отличать спам от обычных сообщений.\n",
    "\n",
    "Реализуйте методы `read_cancer_dataset` и `read_spam_dataset`. Каждый из них принимает на вход путь к набору данных и возвращает выборку `X` и соответствующие метки `y`. Набор данных должен быть упорядочен случайно, т.е. необходимо сделать shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EU8M5Jneas-H"
   },
   "outputs": [],
   "source": [
    "def read_cancer_dataset(path_to_csv: str) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_csv : str\n",
    "        Путь к cancer датасету.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        Матрица признаков опухолей.\n",
    "    y : np.array\n",
    "        Вектор бинарных меток, 1 соответствует доброкачественной опухоли (M), \n",
    "        0 --- злокачественной (B).\n",
    "\n",
    "   \"\"\"\n",
    "    df = pd.read_csv(path_to_csv) #считываем\n",
    "    df.loc[df['label'] == \"M\", 'label'] = 1 #меняем\n",
    "    df.loc[df['label'] == \"B\", 'label'] = 0\n",
    "    df = df.sample(frac=1) #делаем shuffle\n",
    "    Y = df[\"label\"] #отдельно берем таргет\n",
    "    X = df.drop('label', axis=1) #отдельно берем фичи\n",
    "    return np.array(X), np.array(Y)\n",
    "   \n",
    "\n",
    "def read_spam_dataset(path_to_csv: str) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_csv : str\n",
    "        Путь к spam датасету.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        Матрица признаков сообщений.\n",
    "    y : np.array\n",
    "        Вектор бинарных меток, \n",
    "        1 если сообщение содержит спам, 0 если не содержит.\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path_to_csv) #считываем\n",
    "    df = df.sample(frac=1) #делаем shuffle\n",
    "    Y = df[\"label\"] #отдельно берем таргет\n",
    "    X = df.drop('label', axis=1) #отдельно берем фичи\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qg0Tx88ias-P"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X: np.array, y: np.array, ratio: float\n",
    "                     ) -> Tuple[np.array, np.array, np.array, np.array]:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array\n",
    "        Матрица признаков.\n",
    "    y : np.array\n",
    "        Вектор меток.\n",
    "    ratio : float\n",
    "        Коэффициент разделения.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : np.array\n",
    "        Матрица признаков для train выборки.\n",
    "    y_train : np.array\n",
    "        Вектор меток для train выборки.\n",
    "    X_test : np.array\n",
    "        Матрица признаков для test выборки.\n",
    "    y_test : np.array\n",
    "        Вектор меток для test выборки.\n",
    "\n",
    "    \"\"\"\n",
    "    l = int(ratio * X.shape[0])\n",
    "    X_train = X[:l] #берем строки с 0 по l, столбцы все те же\n",
    "    X_test = X[l:]\n",
    "    y_train = y[:l] \n",
    "    y_test = y[l:]\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNT89eekas-S"
   },
   "source": [
    "### Задание 3 (2 балла)\n",
    "Также прежде чем приступать к решению задачи, нам необходимо определиться с метриками, которые позволят нам оценить полученное решение. Для задач классификации мы можем использовать precision, recall и accuracy. Эти метрики считаются для каждого класса.\n",
    "\n",
    "Метод возвращает:\n",
    "\n",
    "* Вектор __Precision__, каждый из элементов которого равен значению метрики precision для соответствующего класса. \n",
    "\n",
    "* Вектор __Recall__, каждый из элементов которого равен значению метрики recall для соответствующего класса.\n",
    "\n",
    "* __Accuracy__ - число, которое равно отношению правильно классифицированных элементов выборке к размеру выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0SsAHQkIas-U"
   },
   "outputs": [],
   "source": [
    "def get_precision_recall_accuracy(y_pred: np.array, y_true: np.array\n",
    "                                  ) -> Tuple[np.array, np.array, float]:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : np.array\n",
    "        Вектор классов, предсказанных моделью.\n",
    "    y_true : np.array\n",
    "        Вектор истинных классов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision : np.array\n",
    "        Вектор с precision для каждого класса.\n",
    "    recall : np.array\n",
    "        Вектор с recall для каждого класса.\n",
    "    accuracy : float\n",
    "        Значение метрики accuracy (одно для всех классов).\n",
    "\n",
    "    \"\"\"\n",
    "    true = sum(y_pred == y_true) #все правильные делить на все неправильные - accuracy\n",
    "    all_dots = y_pred.shape[0]\n",
    "    accuracy = true/all_dots\n",
    "    \n",
    "    precision, recall = np. array([]), np. array([]) \n",
    "    #для того, чтобы посчитать метрики для каждого класса, нам нужно \n",
    "    #посчитать для них TP, FN, FP\n",
    "    #еще надо понять, для чего считать, то есть нам нужен массив с классами\n",
    "    classes = np.unique(y_true)\n",
    "    for item in classes:\n",
    "        TP = sum((y_pred == item) * (y_true == item))\n",
    "        FP = sum((y_pred == item) * (y_true != item))\n",
    "        FN = sum((y_pred != item) * (y_true == item))\n",
    "        precision = np.append(precision, [TP/(TP+FP)])\n",
    "        recall = np.append(recall, [TP/(TP+FN)])\n",
    "    return precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNce2gXfas-d"
   },
   "source": [
    "### Задание 4 (5 баллов)\n",
    "Теперь преступим к реализации классификатора. В этот раз будем использовать классификацию методом k средних. Поскольку основной решаемой задачий во время классификации этим методом является поиск ближайших соседей, а набор данных может быть достаточно большим, наивная реализация будет работать очень долго.\n",
    "\n",
    "Одним из способов решить эту проблему является __KD-дерево__. Оно позволяет значительно ускорить поиск ближайших соседей. Реализуйте построение KD-дерева и выполнение запросов на поиск k ближайших соседей.\n",
    "\n",
    "Метод `__init__` должен принимать на вход набор точек `X`, по которому будет строиться дерево, а так же размер листов `leaf_size` построенного дерева.\n",
    "\n",
    "Метод `query` должен принимать на вход набор точек `X`, для каждой из которых необходимо найти `k` ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4DWLhPpM_hgV"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, value=None, axis=None, data=None):\n",
    "        self.value = value\n",
    "        self.axis = axis\n",
    "        self.data = data\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def single_query(self, root, point, k):\n",
    "\n",
    "        if root.left is None and root.right is None:\n",
    "\n",
    "            neigh_dist = np.sqrt(np.sum((root.data[:, 1:] - point) ** 2, axis=1))\n",
    "            neigh_index = np.argsort(neigh_dist)\n",
    "            index = root.data[neigh_index][:k]\n",
    "            return neigh_dist[neigh_index], index\n",
    "\n",
    "        else:\n",
    "            axis = root.axis - 1\n",
    "            if root.value > point[axis]:\n",
    "                neigh_dist, index = self.single_query(root.left, point, k)\n",
    "                opposite = root.right\n",
    "\n",
    "            else:\n",
    "                neigh_dist, index = self.single_query(root.right, point, k)\n",
    "                opposite = root.left\n",
    "\n",
    "            if neigh_dist[-1] >= np.sqrt(np.sum(point[axis] - root.value) ** 2) or len(index) < k:\n",
    "                opposite_dist, opposite_index = self.single_query(opposite, point, k)\n",
    "                return merge(opposite_index, opposite_dist, index, neigh_dist, k)\n",
    "\n",
    "            return neigh_dist, index\n",
    "\n",
    "\n",
    "def merge(opposite_ind, opposite_dist, index, neigh_dist, k):\n",
    "    i = j = 0\n",
    "    index_merged = []\n",
    "    dist_merged = []\n",
    "    while (i < len(opposite_ind)) and (j < len(index)) and (i + j < k):\n",
    "        if opposite_dist[i] <= neigh_dist[j]:\n",
    "            index_merged.append(opposite_ind[i])\n",
    "            dist_merged.append(opposite_dist[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            index_merged.append(index[j])\n",
    "            dist_merged.append(neigh_dist[j])\n",
    "            j += 1\n",
    "    delta = k - i - j\n",
    "    index_merged.extend(opposite_ind[i: i + delta])\n",
    "    dist_merged.extend(opposite_dist[i: i + delta])\n",
    "    index_merged.extend(index[j: j + delta])\n",
    "    dist_merged.extend(neigh_dist[j: j + delta])\n",
    "    return dist_merged, index_merged\n",
    "\n",
    "\n",
    "class KDTree:\n",
    "\n",
    "    def __init__(self, X, leaf_size=40):\n",
    "        self.X = np.hstack([np.arange(X.shape[0]).reshape(-1, 1), X])\n",
    "        self.dim = X[0].size\n",
    "\n",
    "        self.leaf_size = leaf_size\n",
    "        self.root = self.build_tree(self.X, depth=0)\n",
    "\n",
    "    def build_tree(self, X, depth=0):\n",
    "\n",
    "        axis = (depth % self.dim) + 1\n",
    "        median = np.median(X[:, axis])\n",
    "        left, right = X[X[:, axis] < median], X[X[:, axis] >= median]\n",
    "\n",
    "        if left.shape[0] < self.leaf_size or right.shape[0] < self.leaf_size:\n",
    "            return Node(data=X)\n",
    "\n",
    "        root = Node(value=median, axis=axis)\n",
    "\n",
    "        root.left = self.build_tree(left, depth + 1)\n",
    "        root.right = self.build_tree(right, depth + 1)\n",
    "\n",
    "        return root\n",
    "\n",
    "    def index_extraction(self, point, k=4):\n",
    "        one_point_ans = []\n",
    "        point_neigh = self.root.single_query(self.root, point, k=k)\n",
    "        for index in point_neigh[1]:\n",
    "            one_point_ans.append(int(index[0]))\n",
    "        return one_point_ans\n",
    "\n",
    "    def query(self, X, k=4):\n",
    "        res = []\n",
    "        for point in X:\n",
    "            ans = self.index_extraction(point, k=k)\n",
    "            res.append(ans)\n",
    "        return res\n",
    "\n",
    "\n",
    "def true_closest(X_train, X_test, k):\n",
    "    result = []\n",
    "    for x0 in X_test:\n",
    "        bests = list(sorted([(i, np.linalg.norm(x - x0))\n",
    "                             for i, x in enumerate(X_train)], key=lambda x: x[1]))\n",
    "        bests = [i for i, d in bests]\n",
    "        result.append(bests[:min(k, len(bests))])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG_yIpgCas-i"
   },
   "source": [
    "Поскольку данная струкутра данных является сложной, ее стоит протестировать отдельно. Для этого проведем тестирование с небольшим набором случайных точек. Если после выполнение вывод пуст, то KD-дерево скорее всего работает правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5hF80Ayas-l"
   },
   "source": [
    "### Задание 5  (3 балла)\n",
    "Осталось реализовать сам классификатор. Реализуйте его, используя KD-дерево.\n",
    "\n",
    "Метод `__init__` принимает на вход количество соседей, по которым предсказывается класс, и размер листьев KD-дерева.\n",
    "\n",
    "Метод `fit` должен по набору данных и меток строить классификатор. \n",
    "\n",
    "Метод `predict_proba` должен предсказывать веротности классов для заданного набора данных основываясь на классах соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сделаем класс как в sklearn\n",
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def fit(self, X): #считаем среднее и стандартное отклонение\n",
    "        self.mean = X.mean(axis=0)\n",
    "        self.std = X.std(axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X): #пересчитываем\n",
    "        X = (X - self.mean) / self.std\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X):  #вместе\n",
    "        X = self.fit(X).transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8uYlFIR7as-m"
   },
   "outputs": [],
   "source": [
    "class KNearest:\n",
    "    def __init__(self, n_neighbors: int = 5, leaf_size: int = 30):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_neighbors : int\n",
    "            Число соседей, по которым предсказывается класс.\n",
    "        leaf_size : int\n",
    "            Минимальный размер листа в KD-дереве.\n",
    "\n",
    "        \"\"\"        \n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.leaf_size = leaf_size   \n",
    "    \n",
    "    def fit(self, X: np.array, y: np.array) -> NoReturn:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, по которым строится классификатор.\n",
    "        y : np.array\n",
    "            Метки точек, по которым строится классификатор.\n",
    "\n",
    "        \"\"\"        \n",
    "        self.tree = KDTree(X, self.leaf_size)\n",
    "        self.y = y\n",
    "        \n",
    "    def predict_proba(self, X: np.array) -> List[np.array]:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, для которых нужно определить класс.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list[np.array]\n",
    "            Список np.array (длина каждого np.array равна числу классов):\n",
    "            вероятности классов для каждой точки X.\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        neigh = self.tree.query(X, self.n_neighbors) #вытащили соседей\n",
    "        classes = np.unique(self.y) #посчитали кол-во классов\n",
    "        pred = self.y[neigh] #классы индексов\n",
    "        \n",
    "        proba = np.zeros(shape=(X.shape[0], classes.shape[0])) \n",
    "        \n",
    "        for i, item in enumerate(classes): #считаем, где сколько классов\n",
    "            proba[:, i] = np.sum(pred == item, axis=1)\n",
    "\n",
    "        return proba/self.n_neighbors\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, для которых нужно определить класс.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Вектор предсказанных классов.\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"hw01_task.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}